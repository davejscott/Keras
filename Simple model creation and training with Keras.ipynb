{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(16, input_shape=(1,), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "    ])\n",
    "# model.add(l4) Can also add layers like this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note, Dense is suggesting each layer, this is a 3 layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "train_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    random_younger = randint(13, 64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(1)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "for i in range(1000):\n",
    "    random_younger = randint(13, 64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "train_samples = np.array(train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davescott/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_samples = scaler.fit_transform((train_samples).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 0s - loss: 0.6565 - acc: 0.5405\n",
      "Epoch 2/20\n",
      " - 0s - loss: 0.6249 - acc: 0.6100\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davescott/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2339: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out[0][inputs[2:]] = inputs[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.5827 - acc: 0.6990\n",
      "Epoch 4/20\n",
      " - 0s - loss: 0.5312 - acc: 0.7862\n",
      "Epoch 5/20\n",
      " - 0s - loss: 0.4870 - acc: 0.8129\n",
      "Epoch 6/20\n",
      " - 0s - loss: 0.4455 - acc: 0.8467\n",
      "Epoch 7/20\n",
      " - 0s - loss: 0.4058 - acc: 0.8690\n",
      "Epoch 8/20\n",
      " - 0s - loss: 0.3697 - acc: 0.8900\n",
      "Epoch 9/20\n",
      " - 0s - loss: 0.3374 - acc: 0.9071\n",
      "Epoch 10/20\n",
      " - 0s - loss: 0.3191 - acc: 0.9143\n",
      "Epoch 11/20\n",
      " - 0s - loss: 0.3065 - acc: 0.9233\n",
      "Epoch 12/20\n",
      " - 0s - loss: 0.2973 - acc: 0.9248\n",
      "Epoch 13/20\n",
      " - 0s - loss: 0.2907 - acc: 0.9286\n",
      "Epoch 14/20\n",
      " - 0s - loss: 0.2853 - acc: 0.9286\n",
      "Epoch 15/20\n",
      " - 0s - loss: 0.2809 - acc: 0.9290\n",
      "Epoch 16/20\n",
      " - 0s - loss: 0.2781 - acc: 0.9357\n",
      "Epoch 17/20\n",
      " - 0s - loss: 0.2749 - acc: 0.9324\n",
      "Epoch 18/20\n",
      " - 0s - loss: 0.2728 - acc: 0.9329\n",
      "Epoch 19/20\n",
      " - 0s - loss: 0.2705 - acc: 0.9333\n",
      "Epoch 20/20\n",
      " - 0s - loss: 0.2690 - acc: 0.9381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c16088f60>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_train_samples, train_labels, batch_size=10, epochs=20, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20 Epochs gives an accuracy of over 93% fit for the model. #notbad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1890 samples, validate on 210 samples\n",
      "Epoch 1/20\n",
      " - 0s - loss: 0.2795 - acc: 0.9296 - val_loss: 0.1579 - val_acc: 0.9810\n",
      "Epoch 2/20\n",
      " - 0s - loss: 0.2783 - acc: 0.9360 - val_loss: 0.1556 - val_acc: 0.9762\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davescott/anaconda3/lib/python3.7/site-packages/theano/tensor/subtensor.py:2339: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out[0][inputs[2:]] = inputs[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.2773 - acc: 0.9302 - val_loss: 0.1546 - val_acc: 0.9810\n",
      "Epoch 4/20\n",
      " - 0s - loss: 0.2763 - acc: 0.9333 - val_loss: 0.1538 - val_acc: 0.9810\n",
      "Epoch 5/20\n",
      " - 0s - loss: 0.2757 - acc: 0.9328 - val_loss: 0.1513 - val_acc: 0.9810\n",
      "Epoch 6/20\n",
      " - 0s - loss: 0.2748 - acc: 0.9365 - val_loss: 0.1496 - val_acc: 0.9762\n",
      "Epoch 7/20\n",
      " - 0s - loss: 0.2741 - acc: 0.9349 - val_loss: 0.1487 - val_acc: 0.9810\n",
      "Epoch 8/20\n",
      " - 0s - loss: 0.2733 - acc: 0.9339 - val_loss: 0.1473 - val_acc: 0.9762\n",
      "Epoch 9/20\n",
      " - 0s - loss: 0.2725 - acc: 0.9360 - val_loss: 0.1464 - val_acc: 0.9810\n",
      "Epoch 10/20\n",
      " - 0s - loss: 0.2720 - acc: 0.9376 - val_loss: 0.1453 - val_acc: 0.9810\n",
      "Epoch 11/20\n",
      " - 0s - loss: 0.2713 - acc: 0.9354 - val_loss: 0.1444 - val_acc: 0.9810\n",
      "Epoch 12/20\n",
      " - 0s - loss: 0.2708 - acc: 0.9376 - val_loss: 0.1434 - val_acc: 0.9810\n",
      "Epoch 13/20\n",
      " - 0s - loss: 0.2703 - acc: 0.9333 - val_loss: 0.1427 - val_acc: 0.9810\n",
      "Epoch 14/20\n",
      " - 0s - loss: 0.2697 - acc: 0.9376 - val_loss: 0.1417 - val_acc: 0.9810\n",
      "Epoch 15/20\n",
      " - 0s - loss: 0.2691 - acc: 0.9302 - val_loss: 0.1422 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      " - 0s - loss: 0.2688 - acc: 0.9376 - val_loss: 0.1408 - val_acc: 0.9810\n",
      "Epoch 17/20\n",
      " - 0s - loss: 0.2684 - acc: 0.9386 - val_loss: 0.1393 - val_acc: 0.9810\n",
      "Epoch 18/20\n",
      " - 0s - loss: 0.2678 - acc: 0.9376 - val_loss: 0.1387 - val_acc: 0.9810\n",
      "Epoch 19/20\n",
      " - 0s - loss: 0.2674 - acc: 0.9376 - val_loss: 0.1374 - val_acc: 0.9810\n",
      "Epoch 20/20\n",
      " - 0s - loss: 0.2669 - acc: 0.9381 - val_loss: 0.1365 - val_acc: 0.9810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c16bdd320>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_train_samples, train_labels, validation_split=0.1, batch_size=10, epochs=20, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model is generalizing well on the validation data. Not overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = []\n",
    "test_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    random_younger = randint(13, 64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(1)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(0)\n",
    "    \n",
    "for i in range(200):\n",
    "    random_younger = randint(13, 64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(0)\n",
    "    \n",
    "    random_older = randint(65,100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.array(test_labels)\n",
    "test_samples = np.array(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davescott/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_test_samples = scaler.fit_transform((test_samples).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(scaled_test_samples, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9735085 0.0264915]\n",
      "[0.10687607 0.8931239 ]\n",
      "[0.908297   0.09170299]\n",
      "[0.03740463 0.96259534]\n",
      "[0.97454816 0.02545181]\n",
      "[0.10687607 0.8931239 ]\n",
      "[0.68742335 0.31257668]\n",
      "[0.26353377 0.7364662 ]\n",
      "[0.9769765  0.02302349]\n",
      "[0.03433227 0.9656677 ]\n",
      "[0.95284873 0.04715124]\n",
      "[0.05714262 0.9428574 ]\n",
      "[0.96710396 0.03289602]\n",
      "[0.04828453 0.95171547]\n",
      "[0.97187114 0.02812889]\n",
      "[0.01715956 0.9828404 ]\n",
      "[0.47008812 0.5299119 ]\n",
      "[0.02430868 0.9756913 ]\n",
      "[0.9012102  0.09878978]\n",
      "[0.01872493 0.9812751 ]\n",
      "[0.908297   0.09170299]\n",
      "[0.04074028 0.95925975]\n",
      "[0.9209082  0.07909177]\n",
      "[0.03433227 0.9656677 ]\n",
      "[0.975053   0.02494699]\n",
      "[0.01319576 0.98680425]\n",
      "[0.9740334  0.02596659]\n",
      "[0.12903188 0.8709681 ]\n",
      "[0.93971306 0.06028695]\n",
      "[0.3815565 0.6184435]\n",
      "[0.97242755 0.02757245]\n",
      "[0.02650865 0.9734914 ]\n",
      "[0.9729733  0.02702673]\n",
      "[0.03740463 0.96259534]\n",
      "[0.95284873 0.04715124]\n",
      "[0.33972397 0.66027606]\n",
      "[0.9357315  0.06426853]\n",
      "[0.03150404 0.96849597]\n",
      "[0.51544213 0.48455787]\n",
      "[0.42522302 0.574777  ]\n",
      "[0.96440625 0.03559376]\n",
      "[0.07997793 0.9200221 ]\n",
      "[0.96149606 0.03850393]\n",
      "[0.11747874 0.8825213 ]\n",
      "[0.9012102  0.09878978]\n",
      "[0.07997793 0.9200221 ]\n",
      "[0.8604234  0.13957661]\n",
      "[0.02430868 0.9756913 ]\n",
      "[0.9765097  0.02349033]\n",
      "[0.05253753 0.9474625 ]\n",
      "[0.9682966  0.03170344]\n",
      "[0.11747874 0.8825213 ]\n",
      "[0.8440517 0.1559483]\n",
      "[0.01572294 0.98427707]\n",
      "[0.9769765  0.02302349]\n",
      "[0.33972397 0.66027606]\n",
      "[0.9577705  0.04222945]\n",
      "[0.04828453 0.95171547]\n",
      "[0.9740334  0.02596659]\n",
      "[0.05253753 0.9474625 ]\n",
      "[0.96710396 0.03289602]\n",
      "[0.06212489 0.9378751 ]\n",
      "[0.975053   0.02494699]\n",
      "[0.11747874 0.8825213 ]\n",
      "[0.8846636 0.1153364]\n",
      "[0.1475963 0.8524037]\n",
      "[0.9682966  0.03170344]\n",
      "[0.08817561 0.9118244 ]\n",
      "[0.9577705  0.04222945]\n",
      "[0.33972397 0.66027606]\n",
      "[0.68742335 0.31257668]\n",
      "[0.03433227 0.9656677 ]\n",
      "[0.9682966  0.03170344]\n",
      "[0.1475963 0.8524037]\n",
      "[0.51544213 0.48455787]\n",
      "[0.17187223 0.82812774]\n",
      "[0.8936399  0.10636009]\n",
      "[0.3815565 0.6184435]\n",
      "[0.97072536 0.02927465]\n",
      "[0.02043015 0.97956985]\n",
      "[0.9735085 0.0264915]\n",
      "[0.30025095 0.69974905]\n",
      "[0.6046658  0.39533418]\n",
      "[0.04435974 0.95564026]\n",
      "[0.9209082  0.07909177]\n",
      "[0.17187223 0.82812774]\n",
      "[0.8936399  0.10636009]\n",
      "[0.10687607 0.8931239 ]\n",
      "[0.96710396 0.03289602]\n",
      "[0.3815565 0.6184435]\n",
      "[0.9262381  0.07376187]\n",
      "[0.02890181 0.9710982 ]\n",
      "[0.7597404  0.24025957]\n",
      "[0.02043015 0.97956985]\n",
      "[0.9701356  0.02986437]\n",
      "[0.01872493 0.9812751 ]\n",
      "[0.8440517 0.1559483]\n",
      "[0.02890181 0.9710982 ]\n",
      "[0.6046658  0.39533418]\n",
      "[0.09712493 0.90287507]\n",
      "[0.908297   0.09170299]\n",
      "[0.04074028 0.95925975]\n",
      "[0.97603357 0.02396642]\n",
      "[0.03740463 0.96259534]\n",
      "[0.9695344  0.03046561]\n",
      "[0.03433227 0.9656677 ]\n",
      "[0.97454816 0.02545181]\n",
      "[0.02228711 0.97771287]\n",
      "[0.7913093 0.2086907]\n",
      "[0.17187223 0.82812774]\n",
      "[0.47008812 0.5299119 ]\n",
      "[0.02430868 0.9756913 ]\n",
      "[0.9262381  0.07376187]\n",
      "[0.02890181 0.9710982 ]\n",
      "[0.96710396 0.03289602]\n",
      "[0.02650865 0.9734914 ]\n",
      "[0.8197144  0.18028557]\n",
      "[0.08817561 0.9118244 ]\n",
      "[0.9729733  0.02702673]\n",
      "[0.03150404 0.96849597]\n",
      "[0.8604234  0.13957661]\n",
      "[0.01572294 0.98427707]\n",
      "[0.975053   0.02494699]\n",
      "[0.01872493 0.9812751 ]\n",
      "[0.47008812 0.5299119 ]\n",
      "[0.01572294 0.98427707]\n",
      "[0.9765097  0.02349033]\n",
      "[0.02043015 0.97956985]\n",
      "[0.96710396 0.03289602]\n",
      "[0.05714262 0.9428574 ]\n",
      "[0.9729733  0.02702673]\n",
      "[0.04074028 0.95925975]\n",
      "[0.9577705  0.04222945]\n",
      "[0.01715956 0.9828404 ]\n",
      "[0.97454816 0.02545181]\n",
      "[0.01572294 0.98427707]\n",
      "[0.975053   0.02494699]\n",
      "[0.01572294 0.98427707]\n",
      "[0.9682966  0.03170344]\n",
      "[0.26353377 0.7364662 ]\n",
      "[0.5605429 0.4394571]\n",
      "[0.02430868 0.9756913 ]\n",
      "[0.7597404  0.24025957]\n",
      "[0.03433227 0.9656677 ]\n",
      "[0.91492337 0.0850766 ]\n",
      "[0.2298321 0.7701679]\n",
      "[0.9209082  0.07909177]\n",
      "[0.04435974 0.95564026]\n",
      "[0.96297866 0.03702136]\n",
      "[0.26353377 0.7364662 ]\n",
      "[0.9312357  0.06876432]\n",
      "[0.3815565 0.6184435]\n",
      "[0.64714724 0.3528528 ]\n",
      "[0.01715956 0.9828404 ]\n",
      "[0.8197144  0.18028557]\n",
      "[0.05253753 0.9474625 ]\n",
      "[0.8846636 0.1153364]\n",
      "[0.01319576 0.98680425]\n",
      "[0.64714724 0.3528528 ]\n",
      "[0.01572294 0.98427707]\n",
      "[0.9755481  0.02445191]\n",
      "[0.03150404 0.96849597]\n",
      "[0.8440517 0.1559483]\n",
      "[0.03433227 0.9656677 ]\n",
      "[0.8604234  0.13957661]\n",
      "[0.01440484 0.98559517]\n",
      "[0.9312357  0.06876432]\n",
      "[0.05253753 0.9474625 ]\n",
      "[0.7913093 0.2086907]\n",
      "[0.02430868 0.9756913 ]\n",
      "[0.9701356  0.02986437]\n",
      "[0.02228711 0.97771287]\n",
      "[0.9599345  0.04006553]\n",
      "[0.17187223 0.82812774]\n",
      "[0.9312357  0.06876432]\n",
      "[0.2298321 0.7701679]\n",
      "[0.9577705  0.04222945]\n",
      "[0.02430868 0.9756913 ]\n",
      "[0.47008812 0.5299119 ]\n",
      "[0.06212489 0.9378751 ]\n",
      "[0.93971306 0.06028695]\n",
      "[0.02430868 0.9756913 ]\n",
      "[0.9740334  0.02596659]\n",
      "[0.02430868 0.9756913 ]\n",
      "[0.7597404  0.24025957]\n",
      "[0.3815565 0.6184435]\n",
      "[0.68742335 0.31257668]\n",
      "[0.04435974 0.95564026]\n",
      "[0.9740334  0.02596659]\n",
      "[0.01872493 0.9812751 ]\n",
      "[0.9553743  0.04462571]\n",
      "[0.01715956 0.9828404 ]\n",
      "[0.8846636 0.1153364]\n",
      "[0.11747874 0.8825213 ]\n",
      "[0.97187114 0.02812889]\n",
      "[0.33972397 0.66027606]\n",
      "[0.6046658  0.39533418]\n",
      "[0.11747874 0.8825213 ]\n",
      "[0.93971306 0.06028695]\n",
      "[0.01572294 0.98427707]\n",
      "[0.5605429 0.4394571]\n",
      "[0.08817561 0.9118244 ]\n",
      "[0.8936399  0.10636009]\n",
      "[0.03740463 0.96259534]\n",
      "[0.9209082  0.07909177]\n",
      "[0.07997793 0.9200221 ]\n",
      "[0.9312357  0.06876432]\n",
      "[0.02430868 0.9756913 ]\n",
      "[0.7250556  0.27494442]\n",
      "[0.01715956 0.9828404 ]\n",
      "[0.9689214  0.03107856]\n",
      "[0.10687607 0.8931239 ]\n",
      "[0.9740334  0.02596659]\n",
      "[0.3815565 0.6184435]\n",
      "[0.97454816 0.02545181]\n",
      "[0.11747874 0.8825213 ]\n",
      "[0.9357315  0.06426853]\n",
      "[0.03433227 0.9656677 ]\n",
      "[0.9434629 0.0565371]\n",
      "[0.01872493 0.9812751 ]\n",
      "[0.9701356  0.02986437]\n",
      "[0.04828453 0.95171547]\n",
      "[0.9695344  0.03046561]\n",
      "[0.02228711 0.97771287]\n",
      "[0.96440625 0.03559376]\n",
      "[0.0733264 0.9266736]\n",
      "[0.9755481  0.02445191]\n",
      "[0.01319576 0.98680425]\n",
      "[0.96149606 0.03850393]\n",
      "[0.02430868 0.9756913 ]\n",
      "[0.5605429 0.4394571]\n",
      "[0.04074028 0.95925975]\n",
      "[0.9262381  0.07376187]\n",
      "[0.12903188 0.8709681 ]\n",
      "[0.9469927  0.05300732]\n",
      "[0.26353377 0.7364662 ]\n",
      "[0.9682966  0.03170344]\n",
      "[0.02043015 0.97956985]\n",
      "[0.97187114 0.02812889]\n",
      "[0.02890181 0.9710982 ]\n",
      "[0.9735085 0.0264915]\n",
      "[0.26353377 0.7364662 ]\n",
      "[0.96578074 0.03421925]\n",
      "[0.02228711 0.97771287]\n",
      "[0.97603357 0.02396642]\n",
      "[0.02650865 0.9734914 ]\n",
      "[0.8846636 0.1153364]\n",
      "[0.05714262 0.9428574 ]\n",
      "[0.95018774 0.04981226]\n",
      "[0.05253753 0.9474625 ]\n",
      "[0.9682966  0.03170344]\n",
      "[0.02228711 0.97771287]\n",
      "[0.7597404  0.24025957]\n",
      "[0.02043015 0.97956985]\n",
      "[0.51544213 0.48455787]\n",
      "[0.01319576 0.98680425]\n",
      "[0.9553743  0.04462571]\n",
      "[0.10687607 0.8931239 ]\n",
      "[0.97072536 0.02927465]\n",
      "[0.02890181 0.9710982 ]\n",
      "[0.9262381  0.07376187]\n",
      "[0.01440484 0.98559517]\n",
      "[0.9469927  0.05300732]\n",
      "[0.04828453 0.95171547]\n",
      "[0.9740334  0.02596659]\n",
      "[0.01440484 0.98559517]\n",
      "[0.8440517 0.1559483]\n",
      "[0.3815565 0.6184435]\n",
      "[0.9701356  0.02986437]\n",
      "[0.42522302 0.574777  ]\n",
      "[0.6046658  0.39533418]\n",
      "[0.02650865 0.9734914 ]\n",
      "[0.9577705  0.04222945]\n",
      "[0.01319576 0.98680425]\n",
      "[0.9599345  0.04006553]\n",
      "[0.01319576 0.98680425]\n",
      "[0.91492337 0.0850766 ]\n",
      "[0.42522302 0.574777  ]\n",
      "[0.96297866 0.03702136]\n",
      "[0.04074028 0.95925975]\n",
      "[0.9701356  0.02986437]\n",
      "[0.11747874 0.8825213 ]\n",
      "[0.908297   0.09170299]\n",
      "[0.02650865 0.9734914 ]\n",
      "[0.87338233 0.1266177 ]\n",
      "[0.05714262 0.9428574 ]\n",
      "[0.87338233 0.1266177 ]\n",
      "[0.01319576 0.98680425]\n",
      "[0.64714724 0.3528528 ]\n",
      "[0.12903188 0.8709681 ]\n",
      "[0.8440517 0.1559483]\n",
      "[0.02890181 0.9710982 ]\n",
      "[0.9769765  0.02302349]\n",
      "[0.02650865 0.9734914 ]\n",
      "[0.908297   0.09170299]\n",
      "[0.09712493 0.90287507]\n",
      "[0.8936399  0.10636009]\n",
      "[0.01440484 0.98559517]\n",
      "[0.6046658  0.39533418]\n",
      "[0.04074028 0.95925975]\n",
      "[0.908297   0.09170299]\n",
      "[0.01715956 0.9828404 ]\n",
      "[0.8440517 0.1559483]\n",
      "[0.01440484 0.98559517]\n",
      "[0.9735085 0.0264915]\n",
      "[0.07997793 0.9200221 ]\n",
      "[0.9262381  0.07376187]\n",
      "[0.10687607 0.8931239 ]\n",
      "[0.9469927  0.05300732]\n",
      "[0.03433227 0.9656677 ]\n",
      "[0.97242755 0.02757245]\n",
      "[0.01872493 0.9812751 ]\n",
      "[0.9357315  0.06426853]\n",
      "[0.33972397 0.66027606]\n",
      "[0.97603357 0.02396642]\n",
      "[0.17187223 0.82812774]\n",
      "[0.9469927  0.05300732]\n",
      "[0.2298321 0.7701679]\n",
      "[0.9682966  0.03170344]\n",
      "[0.04828453 0.95171547]\n",
      "[0.9262381  0.07376187]\n",
      "[0.33972397 0.66027606]\n",
      "[0.64714724 0.3528528 ]\n",
      "[0.05253753 0.9474625 ]\n",
      "[0.7597404  0.24025957]\n",
      "[0.02430868 0.9756913 ]\n",
      "[0.51544213 0.48455787]\n",
      "[0.04074028 0.95925975]\n",
      "[0.9695344  0.03046561]\n",
      "[0.05253753 0.9474625 ]\n",
      "[0.91492337 0.0850766 ]\n",
      "[0.05714262 0.9428574 ]\n",
      "[0.97242755 0.02757245]\n",
      "[0.19927402 0.800726  ]\n",
      "[0.9740334  0.02596659]\n",
      "[0.04074028 0.95925975]\n",
      "[0.9357315  0.06426853]\n",
      "[0.02430868 0.9756913 ]\n",
      "[0.9682966  0.03170344]\n",
      "[0.10687607 0.8931239 ]\n",
      "[0.9553743  0.04462571]\n",
      "[0.01440484 0.98559517]\n",
      "[0.975053   0.02494699]\n",
      "[0.03150404 0.96849597]\n",
      "[0.97454816 0.02545181]\n",
      "[0.06751045 0.9324896 ]\n",
      "[0.9765097  0.02349033]\n",
      "[0.02890181 0.9710982 ]\n",
      "[0.8604234  0.13957661]\n",
      "[0.02890181 0.9710982 ]\n",
      "[0.9701356  0.02986437]\n",
      "[0.26353377 0.7364662 ]\n",
      "[0.975053   0.02494699]\n",
      "[0.06212489 0.9378751 ]\n",
      "[0.8846636 0.1153364]\n",
      "[0.06212489 0.9378751 ]\n",
      "[0.97130376 0.02869622]\n",
      "[0.11747874 0.8825213 ]\n",
      "[0.47008812 0.5299119 ]\n",
      "[0.02430868 0.9756913 ]\n",
      "[0.7913093 0.2086907]\n",
      "[0.02228711 0.97771287]\n",
      "[0.96440625 0.03559376]\n",
      "[0.06751045 0.9324896 ]\n",
      "[0.47008812 0.5299119 ]\n",
      "[0.10687607 0.8931239 ]\n",
      "[0.7250556  0.27494442]\n",
      "[0.0733264 0.9266736]\n",
      "[0.51544213 0.48455787]\n",
      "[0.03740463 0.96259534]\n",
      "[0.9735085 0.0264915]\n",
      "[0.05253753 0.9474625 ]\n",
      "[0.8197144  0.18028557]\n",
      "[0.08817561 0.9118244 ]\n",
      "[0.975053   0.02494699]\n",
      "[0.02430868 0.9756913 ]\n",
      "[0.7597404  0.24025957]\n",
      "[0.01715956 0.9828404 ]\n",
      "[0.5605429 0.4394571]\n",
      "[0.06751045 0.9324896 ]\n",
      "[0.97603357 0.02396642]\n",
      "[0.03740463 0.96259534]\n",
      "[0.9682966  0.03170344]\n",
      "[0.01872493 0.9812751 ]\n",
      "[0.9209082  0.07909177]\n",
      "[0.02228711 0.97771287]\n",
      "[0.9765097  0.02349033]\n",
      "[0.2298321 0.7701679]\n",
      "[0.9765097  0.02349033]\n",
      "[0.30025095 0.69974905]\n",
      "[0.87338233 0.1266177 ]\n",
      "[0.05253753 0.9474625 ]\n",
      "[0.47008812 0.5299119 ]\n",
      "[0.01572294 0.98427707]\n",
      "[0.9735085 0.0264915]\n",
      "[0.04435974 0.95564026]\n",
      "[0.7913093 0.2086907]\n",
      "[0.1475963 0.8524037]\n",
      "[0.68742335 0.31257668]\n",
      "[0.11747874 0.8825213 ]\n",
      "[0.9262381  0.07376187]\n",
      "[0.05714262 0.9428574 ]\n",
      "[0.9740334  0.02596659]\n",
      "[0.02890181 0.9710982 ]\n",
      "[0.9012102  0.09878978]\n",
      "[0.0733264 0.9266736]\n",
      "[0.9262381  0.07376187]\n",
      "[0.04074028 0.95925975]\n",
      "[0.9012102  0.09878978]\n",
      "[0.30025095 0.69974905]\n",
      "[0.51544213 0.48455787]\n",
      "[0.02430868 0.9756913 ]\n",
      "[0.9682966  0.03170344]\n",
      "[0.03433227 0.9656677 ]\n",
      "[0.908297   0.09170299]\n",
      "[0.05253753 0.9474625 ]\n",
      "[0.9553743  0.04462571]\n",
      "[0.3815565 0.6184435]\n",
      "[0.7250556  0.27494442]\n",
      "[0.03740463 0.96259534]\n"
     ]
    }
   ],
   "source": [
    "for i in predictions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_predictions = model.predict_classes(scaled_test_samples, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in rounded_predictions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can see these predictions with either a binary or a decimal without roundoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_labels, rounded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[194  16]\n",
      " [  9 201]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c179e9240>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_plot_labels = ['no_side_effects', 'had_side_effects']\n",
    "plot_confusion_matrix(cm, cm_plot_labels, title=\"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrices are a nice way to quickly see how our model is doing on data it hasn't seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
